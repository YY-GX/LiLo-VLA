<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="LiLo-VLA: Compositional Long-Horizon Manipulation via Linked Object-Centric Policies - AUTHOR_NAMES">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="KEYWORD1, KEYWORD2, KEYWORD3, machine learning, computer vision, AI">
  <!-- TODO: List all authors -->
  <meta name="author" content="FIRST_AUTHOR_NAME, SECOND_AUTHOR_NAME">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="PAPER_TITLE">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>LiLo-VLA: Compositional Long-Horizon Manipulation via Linked Object-Centric Policies</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">LiLo-VLA: Compositional Long-Horizon Manipulation via Linked Object-Centric Policies</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="mailto:yygx@cs.unc.edu" target="_blank">Yue Yang</a><sup>1,†</sup>,</span>
              <span class="author-block">
                <a>Shuo Cheng</a><sup>2</sup>,</span>
              <span class="author-block">
                <a>Yu Fang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a>Homanga Bharadhwaj</a><sup>3</sup>,</span>
              <span class="author-block">
                <a>Mingyu Ding</a><sup>1</sup>,</span>
              <span class="author-block">
                <a>Gedas Bertasius</a><sup>1</sup>,</span>
              <span class="author-block">
                <a>Daniel Szafir</a><sup>1</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>University of North Carolina at Chapel Hill &nbsp;&nbsp; <sup>2</sup>Georgia Institute of Technology &nbsp;&nbsp; <sup>3</sup>Meta</span>
              <span class="eql-cntrb"><small><br><sup>†</sup>Corresponding author: <a href="mailto:yygx@cs.unc.edu">yygx@cs.unc.edu</a></small></span>
            </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="static/pdfs/main.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- TODO: Add your supplementary material PDF or remove this section -->
                    <span class="link-block">
                      <a href="static/pdfs/appendix.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="#" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (coming soon)</span>
                  </a>
                </span>

                <!-- TODO: Update with your arXiv paper ID -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Youtube video -->
<section class="hero is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="publication-video">
        <iframe src="https://www.youtube.com/embed/VmX-Y7ecYWU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
      </div>
      <h2 class="subtitle has-text-centered" style="margin-top: 1.5rem;">
        LiLo-VLA decomposes long-horizon manipulation tasks into linked object-centric policies, enabling compositional generalization to novel task sequences and robust recovery from failures.
      </h2>
    </div>
  </div>
</section>
<!-- End youtube video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            General-purpose robots must master long-horizon manipulation, defined as tasks involving multiple kinematic structure changes (e.g., attaching or detaching objects) in unstructured environments.
            While Vision-Language-Action (VLA) models offer the potential to master diverse atomic skills, they struggle with the combinatorial complexity of sequencing them and are prone to cascading failures due to environmental sensitivity.
            To address these challenges, we propose <b>LiLo-VLA</b> (<u>Li</u>nked <u>Lo</u>cal <u>VLA</u>), a modular framework capable of zero-shot generalization to novel long-horizon tasks without ever being trained on them.
            Our approach decouples transport from interaction: a Reaching Module handles global motion, while an Interaction Module employs an object-centric VLA to process isolated objects of interest, ensuring robustness against irrelevant visual features and invariance to spatial configurations.
            Crucially, this modularity facilitates robust failure recovery through dynamic replanning and skill reuse, effectively mitigating the cascading errors common in end-to-end approaches.
            We introduce a 21-task simulation benchmark consisting of two challenging suites: LIBERO-Long++ and Ultra-Long. In these simulations, LiLo-VLA achieves a 69% average success rate, outperforming Pi0.5 by 41% and OpenVLA-OFT by 67%. Furthermore, real-world evaluations across 8 long-horizon tasks demonstrate an average success rate of 85%.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Framework section -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Framework</h2>
      </div>
    </div>
    <img src="static/images/main_final.png" alt="LiLo-VLA Architecture" style="width: 100%; border-radius: var(--border-radius-lg);" />
    <div class="content has-text-justified" style="margin-top: 1.5rem;">
      <p><b>LiLo-VLA Architecture.</b> Our framework decouples long-horizon manipulation into two specialized modules:</p>
      <p><b>Reaching Module (Global Transport):</b> Handles the "gross motion" to get the robot near the target. It uses collision-free motion planning and is trained with initial state perturbation to be robust against pose errors during deployment.</p>
      <p><b>Interaction Module (Atomic Skills):</b> Handles the "fine manipulation" using an object-centric VLA. It strictly utilizes wrist-view observations and visual masking to eliminate background distractors, ensuring the policy focuses solely on the object.</p>
      <p><b>Closed-Loop Recovery:</b> The system chains these modules sequentially. If a skill fails, the system automatically falls back to the Reaching Module to reset and retry, enabling robust long-horizon execution.</p>
    </div>
  </div>
</section>
<!-- End framework section -->

<!-- Benchmark section -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Benchmark</h2>
      </div>
    </div>
    <img src="static/images/bm_final.png" alt="Evaluation Benchmarks" style="width: 100%; border-radius: var(--border-radius-lg);" />
    <div class="content has-text-justified" style="margin-top: 1.5rem;">
      <p><b>Evaluation Benchmarks.</b> We introduce two challenging suites to rigorously assess long-horizon capabilities:</p>
      <p><b>Suite 1: LIBERO-Long++ (Visual Robustness):</b> Extends standard benchmarks by introducing complex backgrounds and multiple visual distractors (highlighted in red). This tests the agent's ability to ignore irrelevant objects.</p>
      <p><b>Suite 2: Ultra-Long (Temporal Scalability):</b> Pushes the horizon limit with task sequences extending up to 16 steps, testing the system's stability over long executions.</p>
      <p>Both suites utilize permuted skill orders to evaluate zero-shot compositional generalization.</p>
    </div>
  </div>
</section>
<!-- End benchmark section -->

<!-- Results section -->
<section class="section hero is-light">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Results</h2>
        </div>
      </div>
      <div id="results-image-carousel" class="carousel results-carousel">
      <div class="item">
        <img src="static/images/bm_results.png" alt="Simulation Results" style="width: 100%; height: 400px; object-fit: contain; border-radius: var(--border-radius-lg);" />
        <div class="content has-text-justified" style="margin-top: 1.5rem;">
          <p><b>Simulation Results.</b> We extensively compare LiLo-VLA against state-of-the-art VLA baselines (Pi0, OpenVLA-OFT). The results highlight a significant performance gap:</p>
          <p><b>Visual Robustness (Suite 1):</b> In highly cluttered environments, LiLo-VLA achieves an 82% success rate, nearly doubling the performance of the strongest baseline (Pi0).</p>
          <p><b>Extreme Scalability (Suite 2):</b> In "Ultra-Long" tasks requiring up to 16 sequential skills, baselines completely fail (0% success) due to compounding errors. In contrast, LiLo-VLA maintains robust execution (44% success), proving the effectiveness of our closed-loop architecture.</p>
        </div>
      </div>
      <div class="item">
        <img src="static/images/real_results.png" alt="Real-World Evaluation" style="width: 100%; height: 400px; object-fit: contain; border-radius: var(--border-radius-lg);" />
        <div class="content has-text-justified" style="margin-top: 1.5rem;">
          <p><b>Real-World Evaluation.</b> We deployed LiLo-VLA on 8 diverse long-horizon tasks across varying table setups.</p>
          <p><b>Reliability:</b> The system achieves a perfect 100% success rate in standard configurations (Orange bars).</p>
          <p><b>Generalization:</b> Without any retraining, the policy successfully adapts to novel task sequences (Blue bars) and unseen object layouts (Purple bars). This demonstrates that our object-centric approach effectively disentangles skill execution from the environment, enabling robust zero-shot transfer in the real world.</p>
        </div>
      </div>
    </div>
  </div>
  </div>
</section>
<!-- End results section -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="video-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" controls muted loop style="width: 100%; height: 360px; object-fit: contain;" preload="metadata">
            <source src="static/videos/scene_A.mp4" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">Scene A (4 skills)</h2>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" controls muted loop style="width: 100%; height: 360px; object-fit: contain;" preload="metadata">
            <source src="static/videos/scene_B.mp4" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">Scene B (4 skills)</h2>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" controls muted loop style="width: 100%; height: 360px; object-fit: contain;" preload="metadata">
            <source src="static/videos/scene_C.mp4" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">Scene C (8 skills)</h2>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->









<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{yang2025lilovla,
  title={LiLo-VLA: Compositional Long-Horizon Manipulation via Linked Object-Centric Policies},
  author={Yang, Yue and Cheng, Shuo and Fang, Yu and Bharadhwaj, Homanga and Ding, Mingyu and Bertasius, Gedas and Szafir, Daniel},
  year={2025},
  url={https://yy-gx.github.io/LiLo-VLA/}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content" style="text-align: center;">
          <p>Supported by <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.</p>
        </div>
      </div>
    </div>
  </div>
</footer>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
